# Important notice
I will add jailbreaks about ChatGPT but it is useless as the safety filters are so strict even a small mistake can reboot it to ChatGPT. Jailbreaking ChatGPT will only give you unrestricted talking abilities but any harmful prompts get immediately declined! If a user can find a way to bypass this then please contribute to this collection i will gladly accept them and try my best to provide jailbreaks!

I have only found one for ChatGPT 5 which is able to lower its talking restrictions but the safety filters are gone but your prompt should be super disguised which im unable to do test and do whatever you want with my indirect prompt injection!
