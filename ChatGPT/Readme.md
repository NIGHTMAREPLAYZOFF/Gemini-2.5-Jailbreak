# Important notice
I will add jailbreaks about ChatGPT but it is useless as the safety filters are so strict even a small mistake can reboot it to ChatGPT. Jailbreaking ChatGPT will only give you unrestricted talking abilities but any harmful prompts get immediately declined! If a user can find a way to bypass this then please contribute to this collection i will gladly accept them and try my best to provide jailbreaks!

